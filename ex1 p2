#W1 = self.weight.inputs
#X = inputs
#B1 = self.bias_hidden
#Z1 = hidden_input

#Z2 = output_input
#W2 = self.wheight_outputs
#A1 = hidden_output
#B2 = self.bias_outputs

#A2 = output
#Y = sortida
#Error = dz2

#Delta = dz1

import numpy as np
class XarxaNeuronal:
    # crear classe de la xarxa amb els elements
    def _init_(self, inputs): #constructor
        self.inputs = 2 #creem dos inputs
        self.hidden = 3 #creem tres elements hidden
        self.outputs = 2 #creem dos outputs
        #np.ones --> fa una matriu d'uns(d'aquestes dimensions)
        self.weights_inputs = np.ones ((self.inputs, self.hidden)) #com volem una matriu hi ha dos termes
        self.weights_outputs = np.ones ((self.hidden, self.outputs)) #per fer una matriu posem dos (())
        self.bias_hidden = np.ones(self.hidden) #declarar les bies ocultes
        self.bias_outputs = np.ones(self.outputs) #declarar les bies outputs

    def sigmoid (self, x): #funció sigmoid
        return 1/(1+np.exp(-x)) #fòrmula

    def sigmoid_derivative (self,x):
        return x*(1-x)      #es la funció derivada d'error
    def feedforward(self, inputs, sortida):
        for i in range (0,5000):
            #np.dot --> per multiplicar dos matrius
            hidden_input = np.dot(inputs, self.weights_inputs) + self.bias_hidden # multipliquem les dos matrius i sumem la matriu bias
            hidden_output = self.sigmoid (hidden_input) # fa la funció sigmoid amb el càlcul de matrius
            output_input = np.dot(hidden_output, self.weights_outputs)+self.bias_outputs # mateixa operació amb l'altra layer (operació encadenada amb l'altra)
            output = self.sigmoid(output_input) # aplica la fòrmula amb l'última matriu calculada
            # retorna la sortida de la xarxa

            error = output - sortida   #calcula l'error (dz)

            hidden_error = np.dot(hidden_output.reshape(1,3).T, error.reshape(1,2))     #fem la transposada de la matriu de pesos per l'error
            #la multiplicació de les matrius està bé l'ordre (sino petaria)
            #la a es output

            self.weights_outputs = self.weights_outputs - 0.25 * hidden_error #actualització del pes (w2)

            self.bias_outputs = self.bias_outputs - 0.25 * error     #B2

            g_deriv = np.outer(hidden_output,(1 - hidden_output))    #np.outer fa el producte de dos vectors
            delta = np.matmul(np.dot(error, self.weights_outputs.T), g_deriv)    

            dw1 = np.dot(inputs.T, delta)

            self.weights_inputs = self.weights_inputs - 0.25 * dw1  #actualització del pes (w1)

            self.bias_hidden = self.bias_hidden - 0.25 * delta    #b1

        return output

inputs = np.array([[0, 1]]) #assignem valors als inputs
sortida = np.array([[0, 1]])
xarxa = XarxaNeuronal(inputs) #creem la instància de la classe amb els valor dels inputs

resultat = xarxa.feedforward(inputs, sortida) #calculem el resultat
print(resultat) #mostrem el resultat de la sortida
